<!doctype html><html itemscope itemtype=http://schema.org/Event><head><meta name=generator content="Hugo 0.154.5"><title itemprop=name>Workshop on Open Challenges for Rigorous Robot Perception</title><meta charset=utf-8><meta name=author content="Workshop on Open Challenges for Rigorous Robot Perception"><meta name=description content><meta name=viewport content="width=device-width"><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><meta property="og:url" content="https://icra2026-rigorous-perception.github.io/"><meta property="og:site_name" content="RIGOROUS Perception"><meta property="og:title" content="RIGOROUS Perception"><meta property="og:locale" content="en"><meta property="og:type" content="website"><meta property="og:image" content="https://icra2026-rigorous-perception.github.io/img/badge.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://icra2026-rigorous-perception.github.io/img/badge.png"><meta name=twitter:title content="RIGOROUS Perception"><link rel="shortcut icon" href=https://icra2026-rigorous-perception.github.io/img/favicon.ico type=image/x-icon><link rel=apple-touch-icon href=https://icra2026-rigorous-perception.github.io/img/badge.png><link rel=stylesheet type=text/css href=https://icra2026-rigorous-perception.github.io/css/main.css><link rel=stylesheet type=text/css href=https://icra2026-rigorous-perception.github.io/css/font-awesome.min.css></head><body><div class=global><nav id=nav><ul class=wrapper><li class=nav-item-title><a href=# title="RIGOROUS Robot Perception @ ICRA'26" class=nav-link-title>RIGOROUS Robot Perception @ ICRA'26</a></li><li class=nav-item><a href=#about title=Overview class=nav-link>Overview</a></li><li class=nav-item><a href=#speakers title=Speakers class=nav-link>Speakers</a></li><li class=nav-item><a href=#schedule title=Schedule class=nav-link>Schedule</a></li><li class=nav-item><a href=#submission title="Call for Papers" class=nav-link>Call for Papers</a></li><li class=nav-item><a href=#dates title="Important Dates" class=nav-link>Important Dates</a></li><li class=nav-item><a href=#organizers title=Organizers class=nav-link>Organizers</a></li></ul></nav><hr><header class=header><div class=wrapper><h1 class=logo-name><a class=logo-link href=# title="Workshop on Open Challenges for Rigorous Robot Perception" itemprop=name>Workshop on Open Challenges for Rigorous Robot Perception</a></h1><h2 class=subtitle></h2><a href=img/floor_plan.pdf target=_blank><h1 class=location-title>Vienna Congress and Convention Center</h1><h2 class=tagline>TBD June 1st or 5th 2026, Vienna</h2></a><a href=https://2026.ieee-icra.org/ target=_blank style=outline:none><img class=title-logo src=img/icra2026.png alt></a></div></header><hr><div class=content id=content><div class=wrapper><section class=about id=about><h2 class=section-title>Overview</h2><p>Robots are increasingly expected to operate in unstructured and dynamic environments. In such environments, robots must be capable of performing complex and diverse tasks, which places new demands on robustness and interpretability of robot perception.</p><p>In this workshop, we aim at examining the state of the art in robot perception and discuss what is still missing for achieving these properties for rigorous robot perception. We will discuss how perception in modular pipelines and in end-to-end learning approaches, e.g., using foundation models such as VLMs or VLAs, can support robustness and interpretability. The intended workshop scope is not limited to visual perception, instead we want to also explore how different modalities (e.g. tactile perception) can contribute to answering above questions. Lastly, in the workshop, we will ask how robustness and interpretability can be assessed for robot systems.</p><p>By invited talks, roundtable discussions, and spotlight/poster presentations of contributed extended abstracts, the workshop provides an opportunity to identify open challenges, assess the promises and limitations of current approaches, and chart new directions for achieving robust and interpretable perception in robotics.</p><div><br><br></div></section><section class=speakers id=speakers><h2 class=section-title>Speakers</h2><ul class=speakers-list><li class=speakers-item itemprop=performer itemscope itemtype=http://schema.org/Person><span class=speaker-photo><img class=photo src=https://icra2026-rigorous-perception.github.io/img/chli.jpg alt="Margarita Chli" itemprop=image></span><h3 class=speakers-name><span>Margarita Chli</span>
<a href target=_blank title></a></h3><h3 class=speakers-university>ETH Zurich and University of Cyprus</h3><p class=speakers-bio>She is an Assistant Professor at the University of Cyprus and ETH Zürich, where she also leads the Vision for Robotics Lab (V4RL). She is a recognized expert in computer vision and robotics, known for her contributions to developing the first fully autonomous helicopter with onboard localization and mapping.</p></li><li class=speakers-item itemprop=performer itemscope itemtype=http://schema.org/Person><span class=speaker-photo><img class=photo src=https://icra2026-rigorous-perception.github.io/img/wang.jpg alt="Xiaolong Wang" itemprop=image></span><h3 class=speakers-name><span>Xiaolong Wang</span>
<a href target=_blank title></a></h3><h3 class=speakers-university>UC San Diego</h3><p class=speakers-bio>He is an Assistant Professor in the ECE department at the University of California, San Diego, and a Visiting Professor at NVIDIA Research. His research focuses on the intersection between computer vision and robotics. His specific interest lies in representation learning with videos and physical robotic interaction data. These comprehensive representations are utilized to facilitate the learning of human-like robot skills, with the goal of generalizing the robot to interact effectively with a wide range of objects and environments in the real physical world.</p></li><li class=speakers-item itemprop=performer itemscope itemtype=http://schema.org/Person><span class=speaker-photo><img class=photo src=https://icra2026-rigorous-perception.github.io/img/alexis.jpg alt="Kostas Alexis" itemprop=image></span><h3 class=speakers-name><span>Kostas Alexis</span></h3><h3 class=speakers-university>Norwegian University of Science and Technology</h3><p class=speakers-bio>He is a Full Professor at the Department of Engineering Cybernetics of the Norwegian University of Science and Technology (NTNU) at Trondheim, Norway. His research goal is to contribute towards establishing true navigational and operational autonomy for robotics.</p></li><li class=speakers-item itemprop=performer itemscope itemtype=http://schema.org/Person><span class=speaker-photo><img class=photo src=https://icra2026-rigorous-perception.github.io/img/xiang.jpg alt="Yu Xiang" itemprop=image></span><h3 class=speakers-name><span>Yu Xiang</span>
<a href target=_blank title></a></h3><h3 class=speakers-university>University of Texas at Dallas</h3><p class=speakers-bio>He is an Assistant Professor in the Department of Computer Science at the University of Texas at Dallas. His research lies at the intersection of robotics and computer vision, with a focus on enabling intelligent systems to perceive, understand, and act in complex 3D environments.</p></li><li class=speakers-item itemprop=performer itemscope itemtype=http://schema.org/Person><span class=speaker-photo><img class=photo src=https://icra2026-rigorous-perception.github.io/img/chalvatzaki.jpg alt="Georgia Chalvatzaki" itemprop=image></span><h3 class=speakers-name><span>Georgia Chalvatzaki</span>
<a href target=_blank title></a></h3><h3 class=speakers-university>TU Darmstadt</h3><p class=speakers-bio>She is a Full Professor at TU Darmstadt, where she leads the Intelligent Robotic Systems for Assistance (iROSA) group. Her research focuses on robot learning for mobile manipulation in assistive robotics, advancing embodied AI through methods at the intersection of machine learning and classical robotics.</p></li><li class=speakers-item itemprop=performer itemscope itemtype=http://schema.org/Person><span class=speaker-photo><img class=photo src=https://icra2026-rigorous-perception.github.io/img/rodriguez.jpg alt="Alberto Rodriguez" itemprop=image></span><h3 class=speakers-name><span>Alberto Rodriguez</span></h3><h3 class=speakers-university>Boston Dynamics</h3><p class=speakers-bio>He is the Director of Robot Behavior for Atlas at Boston Dynamics with prior roles being Associate Professor in the Department of Mechanical Engineering at MIT, leading the MCube lab. His research focuses on robotic manipulation, emphasizing contact mechanics, tactile sensing, and data-driven control methods. His work integrates modeling, planning, and learning to advance manipulation skills in both academic and industrial robotics.</p></li></ul></section><section class=schedule id=schedule><h2 class=section-title>Schedule</h2><p>This is a preliminary version of the schedule and may be subject to change.</p><div class=schedule-tbl><table><thead><tr><th class=schedule-time>Time</th><th class=schedule-slot>Description</th><th class=schedule-description></th></tr></thead><tbody><tr class=schedule-other><td class=schedule-time>8:50</td><td colspan=2 class=schedule-slot>Opening Remarks by the Workshop Organizers</td></tr><tr class=schedule-other><td class=schedule-time>9:00</td><td colspan=2 class=schedule-headline>Topic 1: Perception in Navigation</td></tr><tr><td class=schedule-time>9:00</td><td class=schedule-slot><span class=speaker-photo><img class=photo src=https://icra2026-rigorous-perception.github.io/img/chli.jpg alt="Margarita Chli">
</span>Margarita Chli
<span class=speakers-company>ETH Zurich and University of Cyprus</span></td><td class=schedule-description>TBD (requested: Robustness and Interpretability in Modular Approaches for Navigation)</td></tr><tr><td class=schedule-time>9:30</td><td class=schedule-slot><span class=speaker-photo><img class=photo src=https://icra2026-rigorous-perception.github.io/img/wang.jpg alt="Xiaolong Wang">
</span>Xiaolong Wang
<span class=speakers-company>UC San Diego</span></td><td class=schedule-description>TBD (requested: Robustness and Interpretability in End-to-end Learning Approaches for Navigation)</td></tr><tr class=schedule-other><td class=schedule-time>10:00</td><td colspan=2 class=schedule-slot>Spotlight Talks</td></tr><tr class=schedule-other><td class=schedule-time>10:15</td><td colspan=2 class=schedule-slot>Coffee Break and Poster Session</td></tr><tr><td class=schedule-time>11:00</td><td class=schedule-slot><span class=speaker-photo><img class=photo src=https://icra2026-rigorous-perception.github.io/img/alexis.jpg alt="Kostas Alexis">
</span>Kostas Alexis
<span class=speakers-company>Norwegian University of Science and Technology</span></td><td class=schedule-description>TBD (requested: Robustness and Interpretability in Application-Oriented Approaches for Navigation)</td></tr><tr class=schedule-other><td class=schedule-time>11:30</td><td colspan=2 class=schedule-slot>Roundtable Discussion</td></tr><tr class=schedule-other><td class=schedule-time>12:00</td><td colspan=2 class=schedule-slot>Lunch</td></tr><tr class=schedule-other><td class=schedule-time>13:00</td><td colspan=2 class=schedule-headline>Topic 2: Perception in Manipulation</td></tr><tr><td class=schedule-time>13:00</td><td class=schedule-slot><span class=speaker-photo><img class=photo src=https://icra2026-rigorous-perception.github.io/img/xiang.jpg alt="Yu Xiang">
</span>Yu Xiang
<span class=speakers-company>University of Texas at Dallas</span></td><td class=schedule-description>TBD (requested: Robustness and Interpretability in Modular Approaches for Manipulation)</td></tr><tr><td class=schedule-time>13:30</td><td class=schedule-slot><span class=speaker-photo><img class=photo src=https://icra2026-rigorous-perception.github.io/img/chalvatzaki.jpg alt="Georgia Chalvatzaki">
</span>Georgia Chalvatzaki
<span class=speakers-company>TU Darmstadt</span></td><td class=schedule-description>TBD (requested: Robustness and Interpretability in End-to-end Learning Approaches for Manipulation)</td></tr><tr class=schedule-other><td class=schedule-time>14:00</td><td colspan=2 class=schedule-slot>Spotlight Talks</td></tr><tr class=schedule-other><td class=schedule-time>14:15</td><td colspan=2 class=schedule-slot>Coffee Break and Poster Session</td></tr><tr><td class=schedule-time>15:00</td><td class=schedule-slot><span class=speaker-photo><img class=photo src=https://icra2026-rigorous-perception.github.io/img/rodriguez.jpg alt="Alberto Rodriguez">
</span>Alberto Rodriguez
<span class=speakers-company>Boston Dynamics</span></td><td class=schedule-description>TBD (requested: Robustness and Interpretability in Application-Oriented Approaches for Manipulation)</td></tr><tr class=schedule-other><td class=schedule-time>15:30</td><td colspan=2 class=schedule-slot>Roundtable Discussion</td></tr><tr class=schedule-other><td class=schedule-time>16:00</td><td colspan=2 class=schedule-slot>Closing Remarks</td></tr></tbody></table></div></section><section class=submission id=submission><h2 class=section-title>Call for Papers</h2><p style=margin-bottom:.5em>We invite the submission of field reports or extended abstracts on the following topics of interest:</p><ul class=listing><li style=margin-left:.5em>- <i>Robust perception for navigation in unstructured and dynamic environments</i></li><li style=margin-left:.5em>- <i>Robust perception for manipulation in unstructured and everyday environments</i></li><li style=margin-left:.5em>- <i>Perception in end-to-end learning architectures for robotic navigation and manipulation</i></li><li style=margin-left:.5em>- <i>Interpretability and robustness of perception in end-to-end learning robot systems</i></li><li style=margin-left:.5em>- <i>Uncertainty quantification for robot perception methods</i></li><li style=margin-left:.5em>- <i>Introspection and interpretability of perception methods in robot systems</i></li><li style=margin-left:.5em>- <i>Tactile or visuo-tactile perception for robust contact-rich manipulation in unstructured environments</i></li><li style=margin-left:.5em>- <i>Lessons learned from robot perception in integrated robot systems, incl. informative failure cases</i></li><li style=margin-left:.5em>- <i>Datasets and benchmarks for robustness and interpretability of perception in real-world robot systems</i></li></ul><p style=margin-bottom:.5em>All submitted papers will be reviewed on the basis of technical quality, relevance, significance, and clarity. The page limit of submitted papers is 4 pages including references. We also accept submissions of previously presented work, that you have extended on and work that is being published as part of the ICRA2026 main conference. Upon acceptance, you will be able to present your submission as part of the poster session. Some papers will be selected for oral spotlight presentations. All accepted submissions will be available for the workshop on this website (non archival).</p><p style=margin-bottom:.5em>Please submit your extended abstracts following the ICRA 2026 format guidelines. For details see the following links:</p><ul class=listing><li>- <a href=http://ras.papercept.net/conferences/support/support.php>Format Guidelines</a></li><li>- <a href=http://ras.papercept.net/conferences/support/tex.php>LaTex Template</a></li><li>- <a href=http://ras.papercept.net/conferences/support/word.php>MS Word Template</a></li></ul><p>Please send your submission to <a href=mailto:tbd>TBD</a>.</p></section><section class=dates id=dates><h2 class=section-title>Important Dates</h2><p>Extended Abstract Submission Deadline: April 7, 2026</p><p>Decision Notification: May 8, 2026</p><p>Final Version: May 22, 2026</p><p>Workshop Date: TBD June 1 or 5, 2026</p></section><section class=organizers id=organizers><h2 class=section-title>Organizers</h2><ul class=organizer-list><li class=organizer-item itemprop=performer itemscope itemtype=http://schema.org/Person><span class=organizer-photo><img class=photo src=https://icra2026-rigorous-perception.github.io/img/behley.jpg alt="Jens Behley" itemprop=image></span><h3 class=organizer-name><a class=organizer-name-url href=https://www.ipb.uni-bonn.de/people/jens-behley/ target=_blank title="Jens Behley">Jens Behley</a>
<a href=mailto:jens.behley@igg.uni-bonn.de title="Personal Site"><i class="mail fa fa-envelope" aria-hidden=true></i></a></h3><h3 class=organizer-university>University of Bonn</h3></li><li class=organizer-item itemprop=performer itemscope itemtype=http://schema.org/Person><span class=organizer-photo><img class=photo src=https://icra2026-rigorous-perception.github.io/img/durner.jpg alt="Maximilian Durner" itemprop=image></span><h3 class=organizer-name>Maximilian Durner
<a href=mailto:maximilian.durner@dlr.de title="Personal Site"><i class="mail fa fa-envelope" aria-hidden=true></i></a></h3><h3 class=organizer-university>German Aerospace Center (DLR)</h3></li><li class=organizer-item itemprop=performer itemscope itemtype=http://schema.org/Person><span class=organizer-photo><img class=photo src=https://icra2026-rigorous-perception.github.io/img/hagmanns.jpg alt="Raphael Hagmanns" itemprop=image></span><h3 class=organizer-name><a class=organizer-name-url href=https://raphaelhagmanns.gitlab.io/ target=_blank title="Raphael Hagmanns">Raphael Hagmanns</a>
<a href=mailto:hagmanns@kit.edu title="Personal Site"><i class="mail fa fa-envelope" aria-hidden=true></i></a></h3><h3 class=organizer-university>Fraunhofer IOSB</h3></li><li class=organizer-item itemprop=performer itemscope itemtype=http://schema.org/Person><span class=organizer-photo><img class=photo src=https://icra2026-rigorous-perception.github.io/img/kim.jpg alt="Ayoung Kim" itemprop=image></span><h3 class=organizer-name><a class=organizer-name-url href=https://ayoungk.github.io/ target=_blank title="Ayoung Kim">Ayoung Kim</a></h3><h3 class=organizer-university>Seoul National University</h3></li><li class=organizer-item itemprop=performer itemscope itemtype=http://schema.org/Person><span class=organizer-photo><img class=photo src=https://icra2026-rigorous-perception.github.io/img/miller.jpg alt="Dimity Miller" itemprop=image></span><h3 class=organizer-name><a class=organizer-name-url href=https://research.qut.edu.au/qcr/people/dimity-miller/ target=_blank title="Dimity Miller">Dimity Miller</a>
<a href=mailto:d24.miller@qut.edu.au title="Personal Site"><i class="mail fa fa-envelope" aria-hidden=true></i></a></h3><h3 class=organizer-university>QUT Centre for Robotics</h3></li><li class=organizer-item itemprop=performer itemscope itemtype=http://schema.org/Person><span class=organizer-photo><img class=photo src=https://icra2026-rigorous-perception.github.io/img/stueckler.jpg alt="Joerg Stueckler" itemprop=image></span><h3 class=organizer-name><a class=organizer-name-url href=https://www.uni-augsburg.de/en/fakultaet/fai/informatik/prof/ips/ target=_blank title="Joerg Stueckler">Joerg Stueckler</a>
<a href=mailto:joerg.stueckler@uni-a.de title="Personal Site"><i class="mail fa fa-envelope" aria-hidden=true></i></a></h3><h3 class=organizer-university>University of Augsburg</h3></li><li class=organizer-item itemprop=performer itemscope itemtype=http://schema.org/Person><span class=organizer-photo><img class=photo src=https://icra2026-rigorous-perception.github.io/img/triebel.jpg alt="Rudolph Triebel" itemprop=image></span><h3 class=organizer-name><a class=organizer-name-url href=https://www.dlr.de/en/blog/authors/rudolph-triebel target=_blank title="Rudolph Triebel">Rudolph Triebel</a>
<a href=mailto:rudolph.triebel@dlr.de title="Personal Site"><i class="mail fa fa-envelope" aria-hidden=true></i></a></h3><h3 class=organizer-university>German Aerospace Center (DLR), Karlsruhe Institute of Technology (KIT)</h3></li><li class=organizer-item itemprop=performer itemscope itemtype=http://schema.org/Person><span class=organizer-photo><img class=photo src=https://icra2026-rigorous-perception.github.io/img/yuan.jpg alt="Wenzhen Yuan" itemprop=image></span><h3 class=organizer-name><a class=organizer-name-url href=https://siebelschool.illinois.edu/about/people/department-faculty/yuanwz target=_blank title="Wenzhen Yuan">Wenzhen Yuan</a>
<a href=mailto:yuanwz@illinois.edu title="Personal Site"><i class="mail fa fa-envelope" aria-hidden=true></i></a></h3><h3 class=organizer-university>University of Illinois</h3></li></ul></section><footer class=footer><hr style=display:block;width:100%><p>© 2026 - All Rights Reserved - RIGOROUS Robot Perception Workshop</p></footer></div></div></div><script>window.jQuery||document.write('<script src="https://icra2026-rigorous-perception.github.io/js/jquery.js"><\/script>')</script></body></html>